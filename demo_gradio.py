import gradio as gr
import os
import random

import fcntl

os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)

config_path = "config_temp.txt"
file_path = "file_temp.txt"
with open(config_path, "w") as file:
    fcntl.flock(file, fcntl.LOCK_EX)
    file.write("")
    fcntl.flock(file, fcntl.LOCK_UN)

with open(file_path, "w") as file:
    fcntl.flock(file, fcntl.LOCK_EX)
    file.write("")
    fcntl.flock(file, fcntl.LOCK_UN)

def write_params_to_txt(
    file_path, prompt, width, height, video_length, seed, num_inference_steps
):
    with open(file_path, "w") as file:
        fcntl.flock(file, fcntl.LOCK_EX)
        file.write(f"prompt={prompt}\n")
        file.write(f"width={width}\n")
        file.write(f"height={height}\n")
        file.write(f"video_length={video_length}\n")
        file.write(f"seed={seed}\n")
        file.write(f"num_inference_steps={num_inference_steps}\n")
        fcntl.flock(file, fcntl.LOCK_UN)


def generate_video(prompt, resolution, video_length, seed, num_inference_steps):
    width, height = map(int, resolution.split("x"))

    if seed == -1:
        seed = random.randint(0, 1_000_000)
    write_params_to_txt(
        config_path, prompt, width, height, video_length, seed, num_inference_steps
    )

    flag = 0
    while True:
        with open(file_path, "r") as file:
            for line in file:
                if line.startswith("video_path="):
                    video_path = line.strip().split("=", 1)[1]
                    print(f"video path is :{video_path}")
                    flag = 1
                    break
        if flag == 1:
            break

    with open(config_path, "w") as file:
        fcntl.flock(file, fcntl.LOCK_EX)
        file.write("")
        fcntl.flock(file, fcntl.LOCK_UN)

    with open(file_path, "w") as file:
        fcntl.flock(file, fcntl.LOCK_EX)
        file.write("")
        fcntl.flock(file, fcntl.LOCK_UN)

    return video_path


t2v_prompt_examples = [
    "æ— äººæœºé•œå¤´ä»ç©ºä¸­ä¿¯ç°ï¼Œæ¸æ¸æ¥è¿‘é›„ä¼Ÿçš„å¤§é›å¡”ï¼Œå¡”èº«åœ¨å¤•é˜³çš„é‡‘è‰²ä½™æ™–ä¸­æ˜¾å¾—å°¤ä¸ºåº„ä¸¥ï¼ŒçŠ¹å¦‚ä¸€åº§å¤è€çš„ç¯å¡”ï¼Œå®ˆæŠ¤ç€è¿™ç‰‡å†å²çš„åœŸåœ°ã€‚å‘¨å›´çš„å¹¿åœºå’Œè¡—é“é€æ¸æ˜¾ç°å‡ºç¹å¿™çš„æ™¯è±¡ï¼Œæ¸¸å®¢åœ¨å¡”ä¸‹é©»è¶³ï¼Œå¾®å¼±çš„æ­¥ä¼å£°å’Œäº¤è°ˆå£°è½»è½»ä¼ å…¥è€³ä¸­ã€‚æ— äººæœºé•œå¤´ç¼“æ…¢å‘ä¸Šå‡èµ·ï¼Œå±•ç¤ºå‡ºæ•´ä¸ªå¤§å”ä¸å¤œåŸçš„å£®ä¸½æ™¯è§‚ã€‚è¿œå¤„ï¼Œç°ä»£é«˜æ¥¼å¤§å¦ä¸å¤è€çš„å»ºç­‘èä¸ºä¸€ä½“ï¼Œéœ“è™¹ç¯çš„å…‰è¾‰é—ªçƒï¼Œä¸å¤å¡”çš„é™è°§å½¢æˆé²œæ˜å¯¹æ¯”ã€‚é•œå¤´ç»§ç»­æ‹‰è¿œï¼Œç©¿è¶ŠåŸå¸‚çš„ç©ºä¸­ï¼Œé¸Ÿç°ä¸‹æ–¹é‚£äº›äº¤é”™çš„è¡—é“å’Œç†™ç†™æ”˜æ”˜çš„äººç¾¤ã€‚éšç€å¤œå¹•çš„é™ä¸´ï¼Œæ•´ä¸ªå¤§å”ä¸å¤œåŸé€æ¸ç‚¹äº®ï¼Œéœ“è™¹å’Œç¯å…‰åœ¨å¤œç©ºä¸­æ±‡æˆä¸€ç‰‡ç’€ç’¨çš„æ˜Ÿæµ·ã€‚é•œå¤´é£æ è¿‡è¡—å¤´ï¼Œæ•æ‰åˆ°å„è‰²ç¯å…‰ä¸‹äººä»¬çš„ç¬‘è„¸å’Œå¿™ç¢Œçš„è„šæ­¥ï¼ŒéŸ³ä¹ä¹Ÿåœ¨èƒŒæ™¯ä¸­æ¸æ¸è½¬æ¢æˆèåˆäº†å¤é£å’Œç°ä»£èŠ‚å¥çš„åŠ¨æ„Ÿæ—‹å¾‹ï¼Œå®Œç¾å‘ˆç°å‡ºä¸€ä¸ªæ—¢å¤è€åˆç°ä»£çš„åŸå¸‚é£è²Œã€‚",
    "A stylish woman walks down a Tokyo street filled with warm glowing neon and animatedÂ city signage. She wears a black leather jacket, along red dress, and black boots, and carries aÂ black purse. She wears sunglasses and red lipstick. She walks confidently and casually. TheÂ street is dampand reflective, creating a mirror effect of thecolorful lights. Many pedestrians walk about.",
    "åŠ¨ç”»åœºæ™¯ç‰¹å†™ä¸­ï¼Œä¸€ä¸ªçŸ®å°ã€æ¯›èŒ¸èŒ¸çš„æ€ªç‰©è·ªåœ¨ä¸€æ ¹èåŒ–çš„çº¢èœ¡çƒ›æ—ã€‚ä¸‰ç»´å†™å®çš„è‰ºæœ¯é£æ ¼æ³¨é‡å…‰ç…§å’Œçº¹ç†çš„ç›¸äº’ä½œç”¨ï¼Œåœ¨æ•´ä¸ªåœºæ™¯ä¸­æŠ•å°„å‡ºå¼•äººå…¥èƒœçš„é˜´å½±ã€‚æ€ªç‰©çç€å¥½å¥‡çš„å¤§çœ¼ç›æ³¨è§†ç€ç«ç„°ï¼Œå®ƒçš„çš®æ¯›åœ¨æ¸©æš–é—ªçƒçš„å…‰èŠ’ä¸­è½»è½»æ‹‚åŠ¨ã€‚é•œå¤´æ…¢æ…¢æ‹‰è¿‘ï¼Œæ•æ‰åˆ°æ€ªç‰©çš®æ¯›çš„å¤æ‚ç»†èŠ‚å’Œç²¾è‡´çš„ç†”èœ¡æ¶²æ»´ã€‚æ€ªç‰©è¯•æ¢æ€§åœ°ä¼¸å‡ºä¸€åªçˆªå­ï¼Œä¼¼ä¹æƒ³è¦è§¦ç¢°ç«ç„°ï¼Œè€Œçƒ›å…‰åˆ™åœ¨å®ƒå‘¨å›´é—ªçƒèˆåŠ¨ï¼Œæ°”æ°›å……æ»¡äº†æƒŠå¥‡å’Œå¥½å¥‡ã€‚",
    "A drone camera gracefully circles a historic church perched on a rugged outcropping along the Amalfi Coast, capturing its magnificent architectural details and tiered pathways and patios. Below, waves crash against the rocks, while the horizon stretches out over the coastal waters and hilly landscapes of Italy. Distant figures stroll and enjoy the breathtaking ocean views from the patios, creating a dynamic scene. The warm glow of the afternoon sun bathes the scene in a magical and romantic light, casting long shadows and adding depth to the stunning vista. The camera occasionally zooms in to highlight the intricate details of the church, then pans out to showcase the expansive coastline, creating a captivating visual narrative.",
    "ä¸€ä¸ªç‰¹å†™é•œå¤´æ•æ‰åˆ°ä¸€ä½ 60 å¤šå²ã€ç•™ç€èƒ¡å­çš„ç™½å‘è€äººï¼Œä»–ååœ¨å·´é»çš„ä¸€å®¶å’–å•¡é¦†é‡Œé™·å…¥æ²‰æ€ï¼Œæ€è€ƒç€å®‡å®™çš„å†å²ã€‚ä»–çš„çœ¼ç›ç´§ç´§ç›¯ç€å±å¹•å¤–èµ°åŠ¨çš„äººä»¬ï¼Œè€Œè‡ªå·±å´ä¸€åŠ¨ä¸åŠ¨ã€‚ä»–èº«ç€ç¾Šæ¯›å¤§è¡£ã€çº½æ‰£è¡¬è¡«ã€æ£•è‰²è´é›·å¸½ï¼Œæˆ´ç€ä¸€å‰¯çœ¼é•œï¼Œæ•£å‘ç€æ•™æˆçš„é£èŒƒã€‚ä»–å¶å°”ç¥ä¸€çœ¼å››å‘¨ï¼Œç›®å…‰åœç•™åœ¨èƒŒæ™¯ä¸­ç†™ç†™æ”˜æ”˜çš„å·´é»è¡—é“å’ŒåŸå¸‚æ™¯è§‚ä¸Šã€‚åœºæ™¯æ²æµ´åœ¨é‡‘è‰²çš„å…‰çº¿ä¸­ï¼Œè®©äººè”æƒ³åˆ° 35 æ¯«ç±³ç”µå½±èƒ¶ç‰‡ã€‚å½“ä»–å¾®å¾®å‰å€¾æ—¶ï¼Œçœ¼ç›çå¤§ï¼Œéœ²å‡ºé¡¿æ‚Ÿçš„ç¬é—´ï¼Œå¹¶å¾®å¾®é—­å£å¾®ç¬‘ï¼Œæš—ç¤ºä»–å·²ç»æ‰¾åˆ°äº†ç”Ÿå‘½å¥¥ç§˜çš„ç­”æ¡ˆã€‚æ™¯æ·±è¥é€ å‡ºå…‰å½±äº¤é”™çš„åŠ¨æ€æ•ˆæœï¼Œçƒ˜æ‰˜å‡ºæ™ºæ…§æ²‰æ€çš„æ°›å›´ã€‚",
    "A cheerful otter confidently balances on a surfboard, donning a bright yellow lifejacket, as it glides through the shimmering turquoise waters near lush tropical islands. The scene is rendered in a 3D digital art style, with the sunlight casting playful shadows on the water's surface. The otter occasionally dips its paws into the water, sending up sprays of droplets that catch the light, adding a sense of motion and excitement to the tranquil atmosphere.",
]

t2v_videos_examples = [
    "./examples/output_0.mp4",
    "./examples/output_1.mp4",
    "./examples/output_2.mp4",
    "./examples/output_3.mp4",
    "./examples/output_4.mp4",
    "./examples/output_5.mp4",
]

t2v_examples = [
    [prompt, video] for prompt, video in zip(t2v_prompt_examples, t2v_videos_examples)
]


def create_demo():

    with gr.Blocks() as demo:
        # gr.Markdown("# Open-Sora Plan v1.5 Video Generation")
        LOGO = """
            <center><img src='https://s21.ax1x.com/2024/07/14/pk5pLBF.jpg' alt='Open-Sora Plan logo' style="width:220px; margin-bottom:1px"></center>
        """
        TITLE = """
            <div style="text-align: center; font-size: 45px; font-weight: bold; margin-bottom: 5px;">
                Open-Sora PlanğŸ¤—
            </div>
        """
        DESCRIPTION = """
            <div style="text-align: center; font-size: 16px; font-weight: bold; margin-bottom: 5px;">
                Support Chinese and English; æ”¯æŒä¸­è‹±åŒè¯­
            </div>
            <div style="text-align: center; font-size: 16px; font-weight: bold; margin-bottom: 5px;">
                Welcome to StarğŸŒŸ our <a href='https://github.com/PKU-YuanGroup/Open-Sora-Plan' target='_blank'><b>GitHub</b></a>
            </div>
        """
        gr.HTML(LOGO)
        gr.HTML(TITLE)
        gr.HTML(DESCRIPTION)

        with gr.Row():
            with gr.Column():
                prompt = gr.Textbox(
                    label="Prompt",
                    value="A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, along red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is dampand reflective, creating a mirror effect of thecolorful lights. Many pedestrians walk about.",
                )
                with gr.Row():
                    resolution = gr.Dropdown(
                        choices=[
                            # 720p
                            ("1280x720", "1280x720"),
                            ("720x1280", "720x1280"),
                        ],
                        value="1280x720",
                        label="Resolution",
                    )
                    video_length = gr.Dropdown(
                        label="Video Length",
                        choices=[
                            ("5s (81 frames)", 81),
                        ],
                        value=81,
                    )
                num_inference_steps = gr.Slider(
                    1, 100, value=4, step=1, label="Number of Inference Steps"
                )
                seed = gr.Number(value=-1, label="Seed (-1 for random)")
                generate_btn = gr.Button("Generate")

            with gr.Column():
                output = gr.Video(label="Generated Video")

        generate_btn.click(
            fn=lambda *inputs: generate_video(*inputs),
            inputs=[
                prompt,
                resolution,
                video_length,
                seed,
                num_inference_steps,
            ],
            outputs=output,
        )

        gr.Examples(
            examples=t2v_examples,
            inputs=[prompt, output],
            label="Prompt & Video Examples",
        )

    return demo


if __name__ == "__main__":
    os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"
    server_name = os.getenv("SERVER_NAME", "0.0.0.0")
    server_port = int(os.getenv("SERVER_PORT", "7860"))
    demo = create_demo()
    demo.launch(server_name=server_name, server_port=server_port, share=True)
    # demo.launch(share=True)